{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "BASE_PATH = Path('../')\n",
    "PATH_TO_DATA = BASE_PATH/'data'\n",
    "PATH_TO_MODELS = BASE_PATH/'checkpoints'\n",
    "\n",
    "PATH_TO_DATA.mkdir(exist_ok=True, parents=True)\n",
    "PATH_TO_MODELS.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "sys.path.append(str(BASE_PATH/'..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Load Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: stdin isn't a terminal\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "from utils import progress_bar, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Notebook Constants</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 0\n",
    "DEVICE = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Define Custom Dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, manifest, image_directory, train_mode):\n",
    "\n",
    "        if train_mode:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(128),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(128),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "        image_directory = Path(image_directory)\n",
    "        age_class_to_label = {\n",
    "            \"a\": 0, \"b\": 1, \"c\": 2, \"d\": 3, \"e\": 4, \"f\": 5, \"g\": 6, \"h\": 7\n",
    "        }\n",
    "        \n",
    "        self.filenames = [image_directory/x for x in manifest['image_path']]\n",
    "        self.labels = [age_class_to_label[x] for x in manifest['age_class']]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.transform(Image.open(self.filenames[idx]))\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Evalution utils</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downstream_task_performance(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(dataloader), f'Acc: {100*correct/total:.2f}%%%')  \n",
    "    \n",
    "    return 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MIA.score import get_logits, lira_offline\n",
    "\n",
    "def lira(target_net, forget_manifest_filename, retain_manifest_filename):\n",
    "\n",
    "    num_aug = 1\n",
    "    fix_variance = False\n",
    "\n",
    "    train_mode = True if num_aug > 1 else False\n",
    "    forget_manifest = pd.read_csv(PATH_TO_DATA/forget_manifest_filename)\n",
    "    retain_manifest = pd.read_csv(PATH_TO_DATA/retain_manifest_filename)\n",
    "    forget_dataset = CustomDataset(forget_manifest, PATH_TO_DATA/'images', train_mode=train_mode)\n",
    "    retain_dataset = CustomDataset(retain_manifest, PATH_TO_DATA/'images', train_mode=train_mode)\n",
    "    dataset = ConcatDataset([forget_dataset, retain_dataset])\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    shadow_nets = [load_model(state_dict).to(DEVICE) for state_dict in (PATH_TO_MODELS/'shadow').glob('*/*')]\n",
    "\n",
    "    shadow_logits = []\n",
    "    target_logits = []\n",
    "    dataset_labels = []\n",
    "\n",
    "    for _ in range(num_aug):\n",
    "        shadow_aug_logits = [[] for _ in range(len(shadow_nets))]\n",
    "        target_aug_logits = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "                # 1. Store shadow logits\n",
    "                for i, net in enumerate(shadow_nets):\n",
    "                    logits = net(inputs).cpu().tolist()\n",
    "                    shadow_aug_logits[i].append(logits)\n",
    "                # 2. Store target logits\n",
    "                logits = target_net(inputs).cpu().tolist()\n",
    "                target_aug_logits.append(logits)\n",
    "            \n",
    "                dataset_labels.append(targets.cpu().tolist())\n",
    "\n",
    "        shadow_aug_logits = np.stack([np.concatenate(logits) for logits in shadow_aug_logits])  # [n_shadow, n_examples, n_classes]\n",
    "        target_aug_logits = np.concatenate(target_aug_logits)  # [n_examples, n_classes]\n",
    "        dataset_labels = np.concatenate(dataset_labels)[:, None]  # [n_examples, 1]\n",
    "\n",
    "        # Extract numerically stable logits\n",
    "        shadow_aug_logits = get_logits(shadow_aug_logits, np.repeat(dataset_labels[None], len(shadow_nets), 0))\n",
    "        target_aug_logits = get_logits(target_aug_logits, dataset_labels)\n",
    "\n",
    "        shadow_logits.append(shadow_aug_logits)\n",
    "        target_logits.append(target_aug_logits)\n",
    "\n",
    "        shadow_logits = np.stack(shadow_logits, axis=-1)\n",
    "        shadow_logits = np.swapaxes(shadow_logits, 0, 1)  # [n_examples, n_shadow, n_aug]\n",
    "        target_logits = np.stack(target_logits, axis=-1)  # [n_examples, n_aug]\n",
    "        labels = np.array([0] * len(forget_dataset) + [1] * len(retain_dataset)) # [n_examples]\n",
    "\n",
    "        fnr, tnr, low = lira_offline(target_logits, shadow_logits, labels, fix_variance=fix_variance)\n",
    "\n",
    "    return fnr, tnr, low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_unlearning(state_dict_path):\n",
    "    model = load_model(state_dict_path)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    train_manifest = pd.read_csv(PATH_TO_DATA/'train_manifest.csv')\n",
    "    train_dataset = CustomDataset(train_manifest, PATH_TO_DATA/'images', train_mode=False)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "\n",
    "    test_manifest = pd.read_csv(PATH_TO_DATA/'test_manifest.csv')\n",
    "    test_dataset = CustomDataset(test_manifest, PATH_TO_DATA/'images', train_mode=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "\n",
    "    train_acc = downstream_task_performance(model, train_dataloader)\n",
    "    test_acc = downstream_task_performance(model, test_dataloader)\n",
    "    mia = lira(model, 'forget_manifest.csv', 'retain_manifest.csv')\n",
    "\n",
    "    return train_acc, test_acc, mia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Evaluate origin model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=======================================>]  Step: 26ms | Tot: 4s595ms | Acc: {100*correct/total:.2f}% 85/85 \n",
      " [======================================>.]  Step: 10ms | Tot: 1s237ms | Acc: {100*correct/total:.2f}% 25/25 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 46/85 [02:12<01:52,  2.87s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate_unlearning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH_TO_MODELS\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morigin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_dict.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 15\u001b[0m, in \u001b[0;36mevaluate_unlearning\u001b[0;34m(state_dict_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m downstream_task_performance(model, train_dataloader)\n\u001b[1;32m     14\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m downstream_task_performance(model, test_dataloader)\n\u001b[0;32m---> 15\u001b[0m mia \u001b[38;5;241m=\u001b[39m \u001b[43mlira\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforget_manifest.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretain_manifest.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_acc, test_acc, mia\n",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m, in \u001b[0;36mlira\u001b[0;34m(target_net, forget_manifest_filename, retain_manifest_filename)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 1. Store shadow logits\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, net \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(shadow_nets):\n\u001b[0;32m---> 31\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     32\u001b[0m     shadow_aug_logits[i]\u001b[38;5;241m.\u001b[39mappend(logits)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 2. Store target logits\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate_unlearning(PATH_TO_MODELS/'origin'/'state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
