{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "BASE_PATH = Path('../')\n",
    "PATH_TO_DATA = BASE_PATH/'data'\n",
    "PATH_TO_MODELS = BASE_PATH/'checkpoints'\n",
    "\n",
    "PATH_TO_DATA.mkdir(exist_ok=True, parents=True)\n",
    "PATH_TO_MODELS.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "sys.path.append(str(BASE_PATH/'..'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Load Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "from utils import progress_bar, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Notebook Constants</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 8\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Define Custom Dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, manifest, image_directory, train_mode):\n",
    "\n",
    "        if train_mode:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(128),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(128),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "        image_directory = Path(image_directory)\n",
    "        age_class_to_label = {\n",
    "            \"a\": 0, \"b\": 1, \"c\": 2, \"d\": 3, \"e\": 4, \"f\": 5, \"g\": 6, \"h\": 7\n",
    "        }\n",
    "        \n",
    "        self.filenames = [image_directory/x for x in manifest['image_path']]\n",
    "        self.labels = [age_class_to_label[x] for x in manifest['age_class']]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.transform(Image.open(self.filenames[idx]))\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Evalution utils</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downstream_task_performance(model, dataloader):\n",
    "    model.eval()\n",
    "    top2_correct = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += preds.eq(targets).sum().item()\n",
    "\n",
    "            # Top-2 accuracy.\n",
    "            _, top2_preds = outputs.topk(2, dim=1)\n",
    "            top2_correct += top2_preds.eq(targets.view(-1, 1).expand_as(top2_preds)).any(dim=1).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(dataloader), f'Acc: {100*correct/total:.2f}%%% Top2 Acc: {100*top2_correct/total:.2f}%%%')\n",
    "    \n",
    "    return 100*correct/total, 100*top2_correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MIA.score import get_logits, lira_offline\n",
    "\n",
    "def lira(target_net, forget_manifest_filename, retain_manifest_filename, data_split_filename=None):\n",
    "\n",
    "    num_aug = 1\n",
    "    fix_variance = False\n",
    "\n",
    "    train_mode = True if num_aug > 1 else False\n",
    "    forget_manifest = pd.read_csv(PATH_TO_DATA/forget_manifest_filename)\n",
    "    retain_manifest = pd.read_csv(PATH_TO_DATA/retain_manifest_filename)\n",
    "    forget_dataset = CustomDataset(forget_manifest, PATH_TO_DATA/'images', train_mode=train_mode)\n",
    "    retain_dataset = CustomDataset(retain_manifest, PATH_TO_DATA/'images', train_mode=train_mode)\n",
    "    dataset = ConcatDataset([forget_dataset, retain_dataset])\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    if data_split_filename is not None:\n",
    "        with open(PATH_TO_DATA/data_split_filename, 'rb') as file:\n",
    "            data_split = pickle.load(file)\n",
    "    else:\n",
    "        data_split = None\n",
    "    \n",
    "    shadow_nets = [load_model(state_dict).to(DEVICE) for state_dict in (PATH_TO_MODELS/'shadow').glob('*/*')]\n",
    "\n",
    "    shadow_logits = []\n",
    "    target_logits = []\n",
    "    dataset_labels = []\n",
    "\n",
    "    for _ in range(num_aug):\n",
    "        shadow_aug_logits = [[] for _ in range(len(shadow_nets))]\n",
    "        target_aug_logits = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "                # 1. Store shadow logits\n",
    "                for i, net in enumerate(shadow_nets):\n",
    "                    logits = net(inputs).cpu().tolist()\n",
    "                    shadow_aug_logits[i].append(logits)\n",
    "                # 2. Store target logits\n",
    "                logits = target_net(inputs).cpu().tolist()\n",
    "                target_aug_logits.append(logits)\n",
    "            \n",
    "                dataset_labels.append(targets.cpu().tolist())\n",
    "        \n",
    "\n",
    "        shadow_aug_logits = np.stack([np.concatenate(logits) for logits in shadow_aug_logits])  # [n_shadow, n_examples, n_classes]\n",
    "        target_aug_logits = np.concatenate(target_aug_logits)  # [n_examples, n_classes]\n",
    "        dataset_labels = np.concatenate(dataset_labels)[:, None]  # [n_examples, 1]\n",
    "\n",
    "        # Extract numerically stable logits\n",
    "        shadow_aug_logits = get_logits(shadow_aug_logits, np.repeat(dataset_labels[None], len(shadow_nets), 0))\n",
    "        target_aug_logits = get_logits(target_aug_logits, dataset_labels)\n",
    "\n",
    "        shadow_logits.append(shadow_aug_logits)\n",
    "        target_logits.append(target_aug_logits)\n",
    "\n",
    "    shadow_logits = np.stack(shadow_logits, axis=-1)\n",
    "    shadow_logits = np.swapaxes(shadow_logits, 0, 1)  # [n_examples, n_shadow, n_aug]\n",
    "    target_logits = np.stack(target_logits, axis=-1)  # [n_examples, n_aug]\n",
    "    labels = np.array([0] * len(forget_dataset) + [1] * len(retain_dataset)) # [n_examples]\n",
    "\n",
    "    if data_split is None:\n",
    "        fnr, tnr, auc, low = lira_offline(target_logits, shadow_logits, labels, fix_variance=fix_variance)\n",
    "    else:\n",
    "        in_datasets = [data_split[x.name] for x in dataset.filenames]\n",
    "        fnr, tnr, auc, low = lira_online(target_logits, shadow_logits, labels, in_datasets, fix_variance=fix_variance)\n",
    "\n",
    "    return fnr, tnr, auc, low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_unlearning(model):\n",
    "\n",
    "    train_manifest = pd.read_csv(PATH_TO_DATA/'train_manifest.csv')\n",
    "    train_dataset = CustomDataset(train_manifest, PATH_TO_DATA/'images', train_mode=False)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "\n",
    "    test_manifest = pd.read_csv(PATH_TO_DATA/'test_manifest.csv')\n",
    "    test_dataset = CustomDataset(test_manifest, PATH_TO_DATA/'images', train_mode=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "\n",
    "    train_acc = downstream_task_performance(model, train_dataloader)\n",
    "    test_acc = downstream_task_performance(model, test_dataloader)\n",
    "    mia = lira(model, 'forget_manifest.csv', 'retain_manifest.csv', 'data_split_dict.pickle')\n",
    "\n",
    "    return train_acc, test_acc, mia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Evaluate origin model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=======================================>]  Step: 4ms | Tot: 791ms | Acc: 94.39%%% Top2 Acc: 98.50% 85/85  \n",
      " [======================================>.]  Step: 4ms | Tot: 213ms | Acc: 50.16%%% Top2 Acc: 75.24% 25/25  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:28<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 94.39 top2 train acc: 98.50\n",
      "test acc: 50.16 top2 test acc: 75.24\n",
      "mia: 0.0\n"
     ]
    }
   ],
   "source": [
    "model = load_model(PATH_TO_MODELS/'origin'/'state_dict.pth')\n",
    "model.to(DEVICE)\n",
    "\n",
    "train_acc, test_acc, mia = evaluate_unlearning(model)\n",
    "\n",
    "print(f'train acc: {train_acc[0]:.2f}', f'top2 train acc: {train_acc[1]:.2f}')\n",
    "print(f'test acc: {test_acc[0]:.2f}', f'top2 test acc: {test_acc[1]:.2f}')\n",
    "print(f'mia: {mia[-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Evaluate retrained model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=======================================>]  Step: 4ms | Tot: 823ms | Acc: 91.05%%% Top2 Acc: 96.96% 85/85  ======================>.................]  Step: 7ms | Tot: 454ms | Acc: 89.36%%% Top2 Acc: 96.00% 48/85 \n",
      " [======================================>.]  Step: 6ms | Tot: 212ms | Acc: 46.98%%% Top2 Acc: 75.31% 25/25  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:28<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 91.05 top2 train acc: 96.96\n",
      "test acc: 46.98 top2 test acc: 75.31\n",
      "mia: 0.0\n"
     ]
    }
   ],
   "source": [
    "model = load_model(PATH_TO_MODELS/'retrained'/'state_dict.pth')\n",
    "model.to(DEVICE)\n",
    "\n",
    "train_acc, test_acc, mia = evaluate_unlearning(model)\n",
    "\n",
    "print(f'train acc: {train_acc[0]:.2f}', f'top2 train acc: {train_acc[1]:.2f}')\n",
    "print(f'test acc: {test_acc[0]:.2f}', f'top2 test acc: {test_acc[1]:.2f}')\n",
    "print(f'mia: {mia[-1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Unlearning</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_manifest = pd.read_csv(PATH_TO_DATA/'forget_manifest.csv')\n",
    "retain_manifest = pd.read_csv(PATH_TO_DATA/'retain_manifest.csv')\n",
    "unseen_manifest = pd.read_csv(PATH_TO_DATA/'unseen_manifest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b>Fine Tuning</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_unlearning(model, forget_manifest, retain_manifest, unseen_manifest):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "    dataset = CustomDataset(retain_manifest, PATH_TO_DATA/'images', train_mode=True)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "\n",
    "    num_epochs = 2\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, targets in tqdm(dataloader, desc=f'epoch {epoch}/{num_epochs}', leave=False):\n",
    "            \n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    }
   ],
   "source": [
    "model = load_model(PATH_TO_MODELS/'origin'/'state_dict.pth')\n",
    "model.to(DEVICE)\n",
    "fine_tune_unlearning(model, forget_manifest, retain_manifest, unseen_manifest)\n",
    "\n",
    "train_acc, test_acc, mia = evaluate_unlearning(model)\n",
    "\n",
    "print(f'train acc: {train_acc[0]:.2f}', f'top2 train acc: {train_acc[1]:.2f}')\n",
    "print(f'test acc: {test_acc[0]:.2f}', f'top2 test acc: {test_acc[1]:.2f}')\n",
    "print(f'mia: {mia[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
